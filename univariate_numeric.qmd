# Univariate: Numeric

While we also want to report on the frequency distribution, and central tendency of numeric variables, there are some differences in the way we go about that relative to the techniques we just learned about for categorical variables. 

Additionally, we will need to report on some measures of dispersion that can only be reported for numeric data, such as the standard deviation.

This section will walk us through the process of calculating and reporting necessary elements of a univariate analysis of numeric data.

## Frequency distributions

As we saw when we were recoding `age` earlier in the unit, a frequency table is not really appropriate for numeric data. When there are upwards of 71 different response values---as we have with `age`---a table would be both spatially unwieldy and difficult to interpret.

So, let's start with a style of plotting data that is essentially the barplot of numeric data.

First, let's go ahead and set up our environment by loading in our data and `tidyverse` per usual.

```{r}
library(tidyverse)
load("our_gss.rda")
```
### Histograms

A histogram is the result of taking a numeric variable, slicing it up into equal, ordinal intervals, and then plotting the frequency of each interval. 

There are plenty of other ways for plotting numeric data---some of which we will see later when we focus on visualization---but for now, this is a simple but effective way to get a sense of the distribution of a numeric variable. This is especially important when we need to decide on an appropriate measure of central tendency.

We can create these easily using the `hist()` function, which is in the same family of base R plotting functions as `barplot()`, so much of what we learned for that function will also apply with `hist()`. This function will automatically apply a commonly used method called Sturges's rule to divide our numeric variable into equal bins, so we do not have to specify anything in that regard.

All we need to do is give the `hist()` function our numeric variable. Let's work with the `realrinc`` variable for this example.
```{r}
hist(our_gss$realrinc)
```

Much like we did with `barplot()`, we can clean this up a little by adding a title and a better label for the x axis

```{r}
hist(
  our_gss$realrinc,
  main = "Income distribution of GSS Respondents",
  xlab = "Respondent's income in dollars",
  )
```
Now we have our histogram!

However, this visualization does suggest that we need to do some thinking about the appropriate measure of central tendency for `realrinc`. 

## Central Tendency

For numeric data, any of the 3 common measures of central tendency can be reported. However, the preferred measure for a given variable depends on its distribution.

The mean is always the preferred measure, because it takes into account every single data point in its calculation, and is thus the most comprehensive index of central tendency. 

However, the mean can be misleading in some cases. The distribution should be (basically) normal in order for you to report the mean, and you will want to report the median in most other cases. 

I will first cover the choice of mean or median by revisiting some basics of distributions, and then I will address the rare circumstance where the mode is appropriate.

### Mean or Median?
We saw some typical distributions in our last section on uivariate analysis of categorical data. We'll return to some discussion of those basic distribution types but add a little more context for numeric data that will help us see the impact of making the wrong decision.

I'm going to display a normal distribution, but this time, I'm going to draw a vertical line indicating the location of the mean and median.

```{r, eval = TRUE, echo = FALSE}
ndist <- rnorm(10000)

d <- data.frame(x = 1:length(ndist), y = ndist)

ggplot(d, aes(y)) + 
  geom_histogram(binwidth = .1) +
  geom_vline(aes(xintercept = mean(y), color = "mean")) +
  geom_vline(aes(xintercept = median(y), color = "median"), linetype="dashed") +
  scale_color_manual(name = "stat", values = c(mean = "brown", median = "orange")) +
  labs(
    title = "Normal distribution; n = 10,000",
    x = "Response value",
    y = "Frequency"
  )
```
Now, we can't even really tell the mean and median apart. In fact, in a completely normal distribution, all three of the measures of central tendency will be equal. Remember that real-world data will rarely exhibit perfect normality, but as long as it's reasonably normal, then we can follow convention and report the mean. 



Now, let's look back at `realrinc`.
```{r, eval = TRUE, echo = FALSE}
# Method for using Sturges's rule in bin calculation for ggplot

example <- our_gss

breaks <- pretty(range(example$realrinc, na.rm = TRUE),
                 n = nclass.Sturges(example$realrinc),
                 min.n = 1)



ggplot(our_gss, aes(realrinc)) + 
  geom_histogram(breaks = breaks) +
  geom_vline(aes(xintercept = mean(realrinc, na.rm = TRUE), color = "mean")) +
  geom_vline(aes(xintercept = median(realrinc, na.rm = TRUE), color = "median"), linetype="dashed") +
  scale_color_manual(name = "stat", values = c(mean = "brown", median = "orange")) +
  labs(
    title = "Income distribution of 2022 GSS Respondents",
    x = "Response value",
    y = "Frequency"
  )
```
In the case of `realrinc`, we definitely do not have much normality going on. For one, there are some apparent outlier cases. Much of our data seems to be concentrated within about $0 - $75,000, but then we have a bunch of values at nearly double the maximum of that narrower range. And even within the range where most of our responses are clustered, we have some clear right-skew.

As we can see, because the mean takes all values into account, this makes it susceptible to non-normal distributions. It gets pulled in the direction of the outlier, which, in this case, is also the direction of the skew. 

So, in any case where your numeric variable contains clear outliers and/or exhibits notable skew in either direction, you should report the median rather than the mean.






