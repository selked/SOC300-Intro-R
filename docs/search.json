[
  {
    "objectID": "viz_introduction.html",
    "href": "viz_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Visualization and Analytical Thinking\nUp to this point, we have worked with pretty simple visualizations, just so we can quickly glean important information about our statistical models without spending too much time focusing on the aesthetics of the visuals.\nIn this lab, we will learn a bit more about R’s graphical capability—especially through tidyverse’s ggplot—which provides us with incredible customizability. We will learn how to fine-tune some of the visuals we have already worked with, and we will preview some other common visual styles that can manage with ggplot.\nBefore we start working with some of these new visual tools, I want to take an opportunity to stress the importance of visualization more generally. It’s easy to see the process of presenting visuals as something somewhat superficial, but visualization can be critical for defining the kind of questions we can ask about our data.\nFor now, I’m going to obscure the code I’m using for this document. We will learn more about the kind of commands I used to generate the following figures, but I don’t want anyone to get bogged down initially. I’ll use these visuals to help impart an important lesson about data visualization’s in the research process.",
    "crumbs": [
      "Day 5: Data Visualization and ggplot",
      "Introduction"
    ]
  },
  {
    "objectID": "viz_introduction.html#thirteen-data-sets",
    "href": "viz_introduction.html#thirteen-data-sets",
    "title": "Introduction",
    "section": "Thirteen Data Sets",
    "text": "Thirteen Data Sets\nLet’s take a look at a collection of thirteen different data sets. Each data set has 142 observations with 2 columns, labeled x & y.\nI’ll use some tidyverse commands to get some summary statistics for each of the data sets, including the mean of both variables and their standard deviations. Let’s see what seems to distinguish some of these data sets from one another.\n\n\n# A tibble: 13 × 4\n   mean_x mean_y std_x std_y\n    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1   54.3   47.8  16.8  26.9\n 2   54.3   47.8  16.8  26.9\n 3   54.3   47.8  16.8  26.9\n 4   54.3   47.8  16.8  26.9\n 5   54.3   47.8  16.8  26.9\n 6   54.3   47.8  16.8  26.9\n 7   54.3   47.8  16.8  26.9\n 8   54.3   47.8  16.8  26.9\n 9   54.3   47.8  16.8  26.9\n10   54.3   47.8  16.8  26.9\n11   54.3   47.8  16.8  26.9\n12   54.3   47.8  16.8  26.9\n13   54.3   47.8  16.8  26.9\n\n\nWell, there’s not much we can say here. All the summary statistics are identical. Why don’t we try modeling a linear relationship between the x and y variables. Maybe looking at the correlations will tell us something. I’ll display the linear regression lines for each data set below.\n\n\n\n\n\n\n\n\n\nOkay. This is not revealing much either. All the lines seem to have the same slope, which shows a (slight) negative relationship where y decreases as x increases. The correlations aren’t revealing any notable distinctions.\nBut wait. One thing we can see here is that, while the correlations appear to be about the same, there are some differences in the ranges of values. Note that the regression lines don’t extend across the same range of x-axis values in each data set. Maybe there is something here after all.\nLet’s just go ahead and plot the actual data over our regression lines.\n\n\n\n\n\n\n\n\n\nNow there’s some distinction!\nThis is a tongue in cheek data set known as the ‘datasaurus dozen’. It’s often used in intro statistical classes to help illustrate the importance of visualization. It’s inspired by another conceptually similar data set known as ‘Anscombe’s quartet’ which likewise stresses the role of plotting data in producing well informed analyses.",
    "crumbs": [
      "Day 5: Data Visualization and ggplot",
      "Introduction"
    ]
  },
  {
    "objectID": "viz_introduction.html#in-sum",
    "href": "viz_introduction.html#in-sum",
    "title": "Introduction",
    "section": "In Sum",
    "text": "In Sum\nSo, take this as a showcase of the importance of visualizing your data. This isn’t to discount summary statistics and other numeric description of data—those are still invaluable for us.\nRather, cases like Datasaurus or Anscombe’s quartet highlight the necessity of understanding the shape of your data. This will determine the kind of questions you can ask with the data, as well as the kind of statistical tools you need to describe it.\nFor example, in the case we just examined, those x and y variables do not have any kind of clear linear relationship. In that case, tools like regression that assume linearity are not appropriate. Any relationship between the variables could only be explored through other statistical means.\nSo, making our figures and tables look aesthetically pleasing is indeed valuable in its own right, but don’t underestimate the utility of good visualization for the analytic process itself.",
    "crumbs": [
      "Day 5: Data Visualization and ggplot",
      "Introduction"
    ]
  },
  {
    "objectID": "background.html",
    "href": "background.html",
    "title": "1  Background",
    "section": "",
    "text": "1.1 What is R?\nBefore we start exploring some of R’s basic functionality, I’m going to set the stage a little on what R and R studio are, why we are using these tools in particular, and what we will need to know before we dig in.\nAt it’s core, R is a programming language. There’s a lot to say about this from a computer science perspective, but, for our purposes, you can just think of R as a language with a very particular structure that’s designed to tell our computers what to do.\nThere are all sorts of different programming languages out there, and they all offer certain benefits or cater to particular computing needs. Unlike some general purpose languages like C, C++, or Python, R is relatively specialized, and this is part of what makes it so useful for us. R is designed with statistical computing as a primary motivator, and now—roughly 30 years into its tenure—stands as one of the most widely adopted resources for statistical data science in the social sciences and beyond.\nThough there can be a bit of a learning curve when getting used to R, we will focus on exactly the things that we need and build ourselves up slowly. Once you get used to it, R will allow you to perform incredibly complex statistical procedures with relative ease, and it can even help us with other related tasks like visualizing and presenting our analyses.",
    "crumbs": [
      "Day 1: Getting Started",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "background.html#what-is-r-studio",
    "href": "background.html#what-is-r-studio",
    "title": "1  Background",
    "section": "1.2 What is R Studio?",
    "text": "1.2 What is R Studio?\nWe are going to pair R with the software R Studio, which is what’s known as an Integrated Development Environment (IDE). Programming languages can be leveraged in a number of different ways. You could run R commands entirely from a Windows command line or Mac terminal. But that would probably not be very ideal for us—not to mention sort of ethereal and frustrating for those of without any programming experience. IDEs provide user-friendly interfaces for working with programming languages, so that we can easily manage our code, quickly generate and view the output of our analyses, and generally keep track of what we are doing with R. There are lots of other IDEs out there, but R Studio is an ideal balance of ease and power, so it will serve as our IDE of choice.\nThe best way to think about R Studio’s relationship to R is by framing it as an analogy with a desktop computer. R Studio is to R as a monitor is to a computer. R is the thing that’s doing all the heavy lifting computationally, and R Studio is the thing that allows us to view and interact with R in a way that’s simple and straightforward.",
    "crumbs": [
      "Day 1: Getting Started",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "background.html#acquiring-r-and-r-studio",
    "href": "background.html#acquiring-r-and-r-studio",
    "title": "1  Background",
    "section": "1.3 Acquiring R and R Studio",
    "text": "1.3 Acquiring R and R Studio\nAll of the CHASS computers (and likely most NC State computers) come with R and R Studio, so you do not need to download them, but you may find it convenient to work on R assignments using your own personal device, so I’ve provided some instructions below.\nNote that you will want to install R first,\n\n1.3.1 Downloading R\nYou can download R from the Comprehensive R Archive Network (CRAN).\nWhen you click that link, you will arrive at CRAN’s homepage. Navigate to the sidebar on the left, find ‘Download’ near the top, and then click ‘CRAN’. This will take you to the ‘mirrors’ page. Mirrors are just different host locations for downloading the R installation files. This allows you to maximize download speed by choosing a nearby server, so scroll down to ‘USA’ and choose one of those (I usually opt for the Durham, NC mirror).\nUnless you are very experienced with computers, you should download one of the options listed as ‘pre-compiled binary distributions’. These will typically be the first options listed. Don’t even worry about what that means if you’re not familiar. Just choose the one that reflects your operating system (there are options for Windows, Mac, and Linux) That should download an R installer, and you can follow the directions to complete a default installation.\n\n\n1.3.2 Downloading R Studio\nR Studio is a little more straightforward to download. Just navigate to its homepage, scroll down a little, and you will find a big button that says ‘Download R Studio for [your operating system]’. Go ahead and run the installer with the default settings.",
    "crumbs": [
      "Day 1: Getting Started",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Background</span>"
    ]
  }
]