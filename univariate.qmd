# Univariate Analysis

Before we start examining the relationships between multiple variables, we have to look under the hood of our variables individually and make sure we have a good sense of what they are like. 

We want to know the frequency distribution of the response values, the measures of central tendency, and the dispersion. In other words, we want to see how many respondents chose each response value, which response values are most typical for each variable, and the extent to which the response values vary. 

Luckily for us, R has plenty of tools for generating these quantitative summaries, as well as visualizing them in the form of barcharts, histograms, and other common styles for displaying data.

This tutorial will cover each of these elements, and I will highlight any differences specific to certain levels of measurement along the way.

## Frequency Distributions

### Categorical Variables

#### Frequency tables

Frequency tables are the most effective way to report the frequency distributions for categorical variables. There are actually a ton of different ways to produce this kind of table in R, but we are going to use some convenient functions from the `janitor` package, so let's go ahead and load that in. 

If you are on a lab computer, try to load it with `library()` first. If you get an error, go ahead and install it with `install.packages()` and then load it in.

While we're at it, we'll also bring in `tidyverse` and load in our GSS subset.

```{r, warning = FALSE, message = FALSE}
library(janitor)
library(tidyverse)
load("our_gss.rda")
```

Let's go ahead and work with one of our `partyid` recodes from last time. We'll use `partyid_recoded`, where we retained all the party choices but collapses the categories of degree (e.g. strong democrate + not very strong democrat = Democrat). 

```{r, eval = TRUE, echo = FALSE}
our_gss <- our_gss |>
  mutate(
    partyid_recoded=fct_collapse(partyid, 
"Democrat" = c("strong democrat", "not very strong democrat"),
"Republican" = c("strong republican","not very strong republican"),
"Independent" = c("independent, close to democrat", "independent (neither, no response)", "independent, close to republican"),
"Other Party" = c("other party")
))
```

We can use a simple command with `tabyl()` from the `janitor` package to produce our frequency tables. Let's take a look at some output, and I'll go through a couple details and mention some further specifications we can make.

All we need to do is give our data frame as the first argument, and then our particular variable column as the second argument.

```{r, echo = TRUE, eval = FALSE}
# Without pipe operator
tabyl(our_gss, partyid_recoded)
```
```{r}
# With pipe operator
our_gss |>
  tabyl(partyid_recoded)
```

Now, we have a frequency table for `partyid_recoded`!

Each row is a level of `partyid_recoded`. The `n` column refers to the sample size, so, for example, 1,565 respondents indicated that they were Independents. 

We then have two different columns for percentages. The `percent` column is the proportion of all respondents that chose each response value---while including NA values. Often, we want to get a proportion for only the sample of those who actually answered the question. This is what the `valid_percent` column indicates and is what we are often looking for. 

Let's break it down a little for clarity. 

The total number of respondents is the sum of the `n` column. 

1565 + 1046 + 792 + 106 + 35 = 3,544 (which is also the number of observations in our data frame)

Note that there are 35 observations coded as `NA`, so the total number of *valid* respondents is 3,509.

Now, I'll give the calculations for the `Independent` row.

```{r}
# I'll define a few objects here for simplicity.

all_respondents <- 3544

all_minus_na <- 3509

independents <- 1565

# Percent column

independents / all_respondents

# Valid percent column

independents / all_minus_na

```

In this case, there really aren't that many NA values, so it does not change too much. In general, we will often discard NA categories for the analyses we do for the course, but they give us important information about the survey and can be useful for some questions, so it's important to keep track of them nonetheless. 

Now, let's clean a couple things up and add one extra dimension to this frequency table with the `adorn()` functions.

Let's add a row for totals, turn the proportions into percentages, and round the decimals. We can use the pipe operator to quickly leverage a bunch of different `adorn()` functions.

```{r}
our_gss |>
  tabyl(partyid_recoded) |>
  adorn_totals(where = "row", na.rm = TRUE) |>
  adorn_pct_formatting() |>
  adorn_rounding(digits = 2)
```
  
Lastly, if we want, we can also make the column names a little nicer. It may not be obvious because we've just been displaying this table rather than storing it as an object, but it's actually a data frame, so we can edit the column names directly.

Let's save it as an object so that's easier to see.

```{r}
our_table <- our_gss |>
  tabyl(partyid_recoded) |>
  adorn_totals(where = "row", na.rm = TRUE) |>
  adorn_pct_formatting() |>
  adorn_rounding(digits = 2)
```

We can then use the `colnames()` function to write over the column names. We can just supply our table as an input, and then assign a character vector of our new column names (in the order we want them).

```{r}
colnames(our_table) <- c(
  "Political Party",
  "Frequency",
  "Percent",
  "Valid Percent"
  )

our_table
```
Excellent! We'll learn how to make this even nicer a bit later in the semester, as well as how to export these tables for Word. But this looks pretty good for now.

Let's look at one last visualization technique for categorical variables.

#### Bar plots

For categorical data, bar plots are often the way to go. These typically have the response values on the x axis, and the count or percentage of each response value is tracked on the Y axis. 

Much like with tables, we'll learn some fancier ways to do this later in the semester. But, in the meanwhile, base R has some great plotting functions that can be used very easily without much specification. They're not the prettiest out of the box, but they will do everything we need.

For `barplot()`, we just need the variable column that we are trying to plot. But, there's one thing to remember when you are trying to get a barplot this way---you have to provide the result of `summary(my_variable)` rather than the variable column directly. 

I'll show you a couple ways to do that, which all do the exact same thing.

```{r, eval = FALSE}
# No pipe operator; summary() nested inside barplot()

barplot(summary(our_gss$partyid_recoded))
```

```{r, eval = FALSE}
# With pipe operator
our_gss$partyid_recoded |>
  summary() |>
  barplot()
```

```{r}
# Make separate object for the summary() output

my_summary <- summary(our_gss$partyid_recoded)

barplot(my_summary)
```

Now, as I mentioned, we won't spend too much time adjusting these plots for now, but there's a couple things we can do to make this a little better to look at for now.

For one, our response labels (Democrat, Republican, Independent, etc) are long enough that they get cut off unless we expand the plot margins. Let's go ahead and make the font size a little bit smaller. 

We can add the `cex.names` argument to `barplot()`. This argument takes a number, and the number should reflect an intended proportion of the default font size for our value labels on the x-axis. So, for example, I would enter '2' if I wanted the font to be twice as big. For our purposes, I want to reduce the font a bit, so we'll enter '.75' to reduce the font size by 1/4. 

```{r}
our_gss$partyid_recoded |>
  summary() |>
  barplot(cex.names = .75)
```

Lastly, we can also add some simple descriptive information for the plot, such as a title and labels for the x and y axis. We can do so within `barplot()`

```{r}
our_gss$partyid_recoded |>
  summary() |>
  barplot(
    cex.names = .75, 
    main = "Count of GSS Respondents by Political Party",
    xlab = "Political Party",
    ylab = "Count"
  )
```




